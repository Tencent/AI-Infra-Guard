info:
  name: langchain
  cve: CVE-2025-65106
  summary: LangChain is vulnerable to template injection via attribute access in prompt templates, allowing attackers to access Python object internals.
  details: |
    A template injection vulnerability in LangChain's prompt template system allows attackers to access Python object internals through template syntax. This affects applications accepting untrusted template strings in `ChatPromptTemplate` and related classes. Attackers can traverse object attributes and dictionary lookups (e.g., `__globals__`) to extract sensitive data like environment variables. The vulnerability requires control over the template string itself, not just template variables.
  cvss: CVSS:4.0/AV:N/AC:L/AT:P/PR:N/UI:N/VC:H/VI:L/VA:N/SC:N/SI:N/SA:N
  severity: HIGH
  security_advise: |
    1. Audit your code for any locations where template strings come from untrusted sources.
    2. Update to the patched version of `langchain-core` (>=1.0.7 or >=0.3.80).
    3. Review template usage to ensure separation between template structure and user data.
    4. Consider if templates are necessary; direct message objects often suffice.
    5. Reserve Jinja2 templates for trusted sources only.
rule: version < "1.0.7" || version < "0.3.80"
references:
  - https://github.com/langchain-ai/langchain/security/advisories/GHSA-6qv9-48xg-fc7f
  - https://nvd.nist.gov/vuln/detail/CVE-2025-65106
  - https://github.com/langchain-ai/langchain/commit/c4b6ba254e1a49ed91f2e268e6484011c540542a
  - https://github.com/langchain-ai/langchain/commit/fa7789d6c21222b85211755d822ef698d3b34e00
  - https://github.com/langchain-ai/langchain