info:
  name: langchain
  cve: CVE-2025-68664
  summary: LangChain serialization injection vulnerability enables secret extraction in dumps/loads APIs.
  details: |
    A serialization injection vulnerability exists in LangChain's `dumps()` and `dumpd()` functions due to improper escaping of dictionaries with `'lc'` keys. This allows attackers to inject malicious LangChain object structures, leading to secret extraction (e.g., environment variables) and class instantiation with attacker-controlled parameters, potentially triggering side effects like network calls or file operations.
  cvss: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:L/A:N
  severity: CRITICAL
  security_advise: |
    1. Upgrade `langchain-core` to version `1.2.5` or higher.
    2. Upgrade `langchain-core` to version `0.3.81` or higher if using an older major version.
    3. When deserializing custom classes, explicitly specify allowed objects using the `allowed_objects` parameter in `load()` or `loads()`.
    4. If Jinja2 templates are required, pass `init_validator=None` to `load()` or `loads()`, but only if the serialized data is trusted.
    5. If loading secrets from environment variables is necessary, explicitly set `secrets_from_env=True` in `load()` or `loads()`.
rule: (version > "0" && version < "0.3.81") || (version >= "1.0.0" && version < "1.2.5")
references:
  - https://github.com/langchain-ai/langchain/security/advisories/GHSA-c67j-w6g6-q2cm
  - https://nvd.nist.gov/vuln/detail/CVE-2025-68664
  - https://github.com/langchain-ai/langchain/pull/34455
  - https://github.com/langchain-ai/langchain/pull/34458
  - https://github.com/langchain-ai/langchain/commit/5ec0fa69de31bbe3d76e4cf9cd65a6accb8466c8
  - https://github.com/langchain-ai/langchain/commit/d9ec4c5cc78960abd37da79b0250f5642e6f0ce6
  - https://github.com/langchain-ai/langchain
  - https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D0.3.81
  - https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.5