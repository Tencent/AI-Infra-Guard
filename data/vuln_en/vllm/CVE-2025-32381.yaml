info:
  name: vllm
  cve: CVE-2025-32381
  summary: xgrammar vulnerable to Denial of Service via unbounded cache memory usage
  details: |
    The xgrammar library used in vLLM implements a cache for compiled grammars to improve performance. However, this cache was unbounded, allowing attackers to exhaust system memory by sending numerous requests with unique JSON schemas, resulting in a denial of service.
    The issue has been addressed by introducing a bounded cache size in xgrammar version 0.1.18. An example integration of this fix within vLLM can be seen in PR #16283.
  cvss: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H
  severity: HIGH
  security_advise: |
    1. Upgrade `xgrammar` dependency to version >= 0.1.18
    2. If using custom grammar caching, implement size limits on caches
    3. Monitor resource usage in LLM inference services exposed to untrusted inputs
rule: version >= "0" && version < "0.1.18"
references:
  - https://github.com/mlc-ai/xgrammar/security/advisories/GHSA-389x-67px-mjg3
  - https://nvd.nist.gov/vuln/detail/CVE-2025-32381
  - https://github.com/mlc-ai/xgrammar/pull/243
  - https://github.com/vllm-project/vllm/pull/16283
  - https://github.com/mlc-ai/xgrammar