info:
  name: vllm
  cve: CVE-2025-62164
  summary: vLLM deserialization vulnerability leading to DoS and potential RCE.
  details: |
    A memory corruption vulnerability exists in vLLM versions 0.10.2 and later, specifically in the Completions API endpoint.
    This vulnerability allows for a denial-of-service (DoS) and potentially remote code execution (RCE) due to insufficient validation when loading user-supplied prompt embeddings with `torch.load()`.
    Maliciously crafted tensors can bypass internal bounds checks, triggering an out-of-bounds memory write during the `to_dense()` call, which can crash vLLM or lead to code execution.
  cvss: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H
  severity: HIGH
  security_advise: |
    1. Upgrade vLLM to version 0.11.1 or later.
    2. Implement strict validation for user-supplied prompt embeddings.
    3. Ensure `torch.sparse.check_sparse_tensor_invariants` context manager is used when loading sparse tensors if using PyTorch 2.8.0 or later.
rule: version >= "0.10.2" && version < "0.11.1"
references:
  - https://github.com/vllm-project/vllm/security/advisories/GHSA-mrw7-hf4f-83pf
  - https://nvd.nist.gov/vuln/detail/CVE-2025-62164
  - https://github.com/vllm-project/vllm/pull/27204
  - https://github.com/vllm-project/vllm/commit/58fab50d82838d5014f4a14d991fdb9352c9c84b