info:
  name: vllm
  cve: CVE-2026-22807
  summary: vLLM is vulnerable to Remote Code Execution (RCE) due to insecure dynamic module loading during model initialization.
  details: |
    vLLM loads Hugging Face `auto_map` dynamic modules during model resolution without gating on `trust_remote_code`.
    This allows attacker-controlled Python code in a model repository or path to execute at server startup,
    leading to arbitrary code execution on the vLLM host during model load, even before any request handling and without requiring API access.
  cvss: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H
  severity: HIGH
  security_advise: |
    1. Upgrade vLLM to version 0.14.0 or later.
    2. Ensure that `trust_remote_code` is properly configured and enforced when loading models from untrusted sources.
    3. Review and restrict access to model repositories and paths to prevent the introduction of malicious code.
rule: version > "0.10.1" && version < "0.14.0"
references:
  - https://github.com/vllm-project/vllm/security/advisories/GHSA-2pc9-4j83-qjmr
  - https://nvd.nist.gov/vuln/detail/CVE-2026-22807
  - https://github.com/vllm-project/vllm/pull/32194
  - https://github.com/vllm-project/vllm/commit/78d13ea9de4b1ce5e4d8a5af9738fea71fb024e5
  - https://github.com/vllm-project/vllm
  - https://github.com/vllm-project/vllm/releases/tag/v0.14.0